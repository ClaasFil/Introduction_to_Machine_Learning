{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Kernelized SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images is 1797 and each image contains 64 pixels\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target == 8\n",
    "print(\n",
    "    f\"The number of images is {X.shape[0]} and each image contains {X.shape[1]} pixels\"\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF-Kernel\n",
    "<br>\n",
    "\n",
    "Calculation of a reference accuracy without hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference accuracy without hyperparameter tuning: 0.987037037037037\n"
     ]
    }
   ],
   "source": [
    "reference_model = make_pipeline( SVC(kernel='rbf'))\n",
    "reference_model.fit(X, y)\n",
    "reference_model.fit(X_train, y_train)\n",
    "y_pred_ref = reference_model.predict(X_test)      \n",
    "\n",
    "print(\"Reference accuracy without hyperparameter tuning: \"+ str( accuracy_score(y_test, y_pred_ref)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every fitting process is quite equivalent. At first, the Parameter gid gets defined. Then a grid search gets performed where for each parameter set and SVC gets calculated. The parameter set of the model with the best accuracy ist selected and displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best kernel has these params: {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      " The model provides an test accuracy of: 0.9925925925925926 on the test set, \n",
      " as well as an train accuracy of: 0.9992044550517104 on the training set\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [\n",
    "    {\"kernel\": [\"rbf\"], \"gamma\": [1e-2, 1e-4], \"C\": [ 1, 10, 100, 1000]}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(     \n",
    "    SVC(), tuned_parameters)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_pred_test = grid_search.predict(X_test)      \n",
    "y_pred_train = grid_search.predict(X_train)      \n",
    "print(\"The best kernel has these params: \" + str(grid_search.best_params_)+ \"\\n The model provides an test accuracy of: \"+ str( accuracy_score(y_test, y_pred_test)) + \" on the test set, \\n as well as an train accuracy of: \"+ str( accuracy_score(y_train, y_pred_train)) + \" on the training set\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with tuned parameters provides an accuracy of  0.9926 and the reference one of  0.9870. For that reason, the tuned parameter achieved a better result than the reference parameters. <br>\n",
    "The parameters \"C\" and \"gamma\" were tuned with GridSearchCV. These Parameters were selected because they are the only ones influencing the RBF kernel. Other parameters like \"degree\" could be set but would not be considered in an RBF kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear-Kernel\n",
    "<br>\n",
    "\n",
    "Calculation of a reference accuracy without hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference accuracy without hyperparameter tuning: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "reference_model = make_pipeline( SVC(kernel='linear'))\n",
    "reference_model.fit(X, y)\n",
    "reference_model.fit(X_train, y_train)\n",
    "y_pred_ref = reference_model.predict(X_test)      \n",
    "\n",
    "print(\"Reference accuracy without hyperparameter tuning: \"+ str( accuracy_score(y_test, y_pred_ref)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best kernel has these params: {'C': 0.001, 'kernel': 'linear'}\n",
      " The model provides an test accuracy of: 0.9555555555555556 on the test set, \n",
      " as well as an train accuracy of: 0.9705648369132857 on the training set\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [\n",
    "    {\"kernel\": [\"linear\"], \"C\": [0.001, 0.01, 0.1, 1, 10]},\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(                                            \n",
    "    SVC(), tuned_parameters     \n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_pred_test = grid_search.predict(X_test)      \n",
    "y_pred_train = grid_search.predict(X_train)      \n",
    "print(\"The best kernel has these params: \" + str(grid_search.best_params_)+ \"\\n The model provides an test accuracy of: \"+ str( accuracy_score(y_test, y_pred_test)) + \" on the test set, \\n as well as an train accuracy of: \"+ str( accuracy_score(y_train, y_pred_train)) + \" on the training set\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with tuned parameters provides an accuracy of  0.9519 and the reference one of  0.9444. For that reason, the tuned parameter achieved a better result than the reference parameters. <br>\n",
    "Only the parameter was \"C\" tuned with GridSearchCV because the other parameters don't affect a linear Kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly-Kernel\n",
    "<br>\n",
    "\n",
    "Calculation of a reference accuracy without hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference accuracy without hyperparameter tuning: 0.9907407407407407\n"
     ]
    }
   ],
   "source": [
    "reference_model = make_pipeline( SVC(kernel='poly'))\n",
    "reference_model.fit(X, y)\n",
    "reference_model.fit(X_train, y_train)\n",
    "y_pred_ref = reference_model.predict(X_test)      \n",
    "\n",
    "print(\"Reference accuracy without hyperparameter tuning: \"+ str( accuracy_score(y_test, y_pred_ref)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best kernel has these params: {'C': 10, 'coef0': 0, 'degree': 4, 'gamma': 0.001, 'kernel': 'poly'}\n",
      " The model provides an test accuracy of: 0.9944444444444445 on the test set, \n",
      " as well as an train accuracy of: 1.0 on the training set\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [\n",
    "    {\"kernel\": [\"poly\"],\"coef0\":[-1,0,1,10,100], \"gamma\": [1e-3, 1e-4], \"C\": [10, 100, 1000], \"degree\": [1, 2, 3,4,5]},\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(                                           \n",
    "    SVC(), tuned_parameters                                                                          \n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_pred_test = grid_search.predict(X_test)      \n",
    "y_pred_train = grid_search.predict(X_train)      \n",
    "print(\"The best kernel has these params: \" + str(grid_search.best_params_)+ \"\\n The model provides an test accuracy of: \"+ str( accuracy_score(y_test, y_pred_test)) + \" on the test set, \\n as well as an train accuracy of: \"+ str( accuracy_score(y_train, y_pred_train)) + \" on the training set\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with tuned parameters provides an accuracy of  0.9944 and the reference one of  0.9907. For that reason, the tuned parameter achieved a better result than the reference parameters. <br>\n",
    "The parameters \"C\", \"gamma\" and \"coef0\" where tuned with GridSearchCV. These Parameters were selected because they are the only ones influencing the poly kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid-Kernel\n",
    "<br>\n",
    "\n",
    "Calculation of a reference accuracy without hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference accuracy without hyperparameter tuning: 0.8796296296296297\n"
     ]
    }
   ],
   "source": [
    "reference_model = make_pipeline( SVC(kernel='sigmoid'))\n",
    "reference_model.fit(X, y)\n",
    "reference_model.fit(X_train, y_train)\n",
    "y_pred_ref = reference_model.predict(X_test)      \n",
    "\n",
    "print(\"Reference accuracy without hyperparameter tuning: \"+ str( accuracy_score(y_test, y_pred_ref)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best kernel has these params: {'C': 1000, 'coef0': -1, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      " The model provides an test accuracy of: 0.9925925925925926 on the test set, \n",
      " as well as an train accuracy of: 1.0 on the training set\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [\n",
    "    {\"kernel\": [\"sigmoid\"],\"coef0\":[-10,-1,0,1,10,100], \"gamma\": [1e-3, 1e-4], \"C\": [10, 100, 1000]},\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(                                        \n",
    "    SVC(), tuned_parameters                                                                \n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_pred_test = grid_search.predict(X_test)      \n",
    "y_pred_train = grid_search.predict(X_train)      \n",
    "print(\"The best kernel has these params: \" + str(grid_search.best_params_)+ \"\\n The model provides an test accuracy of: \"+ str( accuracy_score(y_test, y_pred_test)) + \" on the test set, \\n as well as an train accuracy of: \"+ str( accuracy_score(y_train, y_pred_train)) + \" on the training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with tuned parameters provides an accuracy of  0.9926 and the reference one of  0.8796. For that reason, the tuned parameter achieved a better result than the reference parameters. <br>\n",
    "The parameters \"C\", \"gamma\" and \"coef0\" where tuned with GridSearchCV. These Parameters were selected because they are the only ones influencing the poly kernel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
